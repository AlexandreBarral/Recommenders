{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering Recommendation Algorithm Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This illustrative comparison applies to collaborative filtering algorithms available in this repository such as Spark ALS, Surprise SVD and SAR. These algorithms are usable in a variety of recommendation tasks, including product or news recommendations. \n",
    "\n",
    "The main purpose of this notebook is not to produce comprehensive benchmarking results on multiple datasets. Rather, it is intended to illustrate on how one could evaluate different recommender algorithms using tools in this repository.\n",
    "\n",
    "## Experimentation setup:\n",
    "* Objective\n",
    "  * To compare how each collaborative filtering algorithm perform in predicting ratings and recommending relevant items.\n",
    "* Environment\n",
    "  * The comparison is run on a [Azure Data Science Virtual Machine](https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/). \n",
    "  * The virtual machine size is Standard NC6s_v2 (6 vcpus, 112 GB memory).\n",
    "  * It should be noted that the single node DSVM is not supposed to run scalable benchmarking analysis. Either scaling up or out the computing instances is necessary to run the benchmarking in an run-time efficient way without any memory issue.\n",
    "* Datasets\n",
    "  * [Movielens 100K](https://grouplens.org/datasets/movielens/100k/).\n",
    "  * [Movielens 1M](https://grouplens.org/datasets/movielens/1m/).\n",
    "* Data split\n",
    "  * The data is split into train and test sets.\n",
    "  * The split ratios are 75-25 for train and test datasets.\n",
    "  * The splitting is random. \n",
    "* Model training\n",
    "  * A recommendation model is trained by using each of the collaborative filtering algorithms. \n",
    "  * Empirical parameter values reported [here](http://mymedialite.net/examples/datasets.html) are used in this notebook.  More exhaustive hyper parameter tuning would be required to further optimize results.\n",
    "* Evaluation metrics\n",
    "  * Ranking metrics:\n",
    "    * Precision@k.\n",
    "    * Recall@k.\n",
    "    * Normalized discounted cumulative gain@k (NDCG@k).\n",
    "    * Mean-average-precision (MAP). \n",
    "    * In the evaluation metrics above, k = 10. \n",
    "  * Rating metrics:\n",
    "    * Root mean squared error (RMSE).\n",
    "    * Mean average error (MAE).\n",
    "    * R squared.\n",
    "    * Explained variance.\n",
    "  * Run time performance\n",
    "    * Elapsed for training a model and using a model for predicting/recommending k items. \n",
    "    * The time may vary across different machines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) \n",
      "[GCC 7.3.0]\n",
      "Pandas version: 0.24.1\n",
      "PySpark version: 2.3.1\n",
      "Surprise version: 1.0.6\n",
      "PyTorch version: 1.0.0\n",
      "Fast AI version: 1.0.45\n",
      "Tensorflow version: 1.12.0\n",
      "CUDA version: CUDA Version 9.1.85\n",
      "CuDNN version: 7.0.5\n",
      "Number of cores: 24\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import papermill as pm\n",
    "import pyspark\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import StringType, FloatType, IntegerType, LongType\n",
    "import torch\n",
    "import fastai\n",
    "from fastai.collab import EmbeddingDotBias, collab_learner, CollabDataBunch\n",
    "import tensorflow as tf\n",
    "import surprise\n",
    "\n",
    "from reco_utils.common.python_utils import get_number_processors\n",
    "from reco_utils.common.timer import Timer\n",
    "from reco_utils.common.gpu_utils import get_cuda_version, get_cudnn_version\n",
    "from reco_utils.common.spark_utils import start_or_get_spark\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.sparse import AffinityMatrix\n",
    "from reco_utils.dataset.python_splitters import python_chrono_split\n",
    "from reco_utils.recommender.sar.sar_singlenode import SARSingleNode\n",
    "from reco_utils.recommender.ncf.ncf_singlenode import NCF\n",
    "from reco_utils.recommender.ncf.dataset import Dataset as NCFDataset\n",
    "from reco_utils.recommender.rbm.rbm import RBM\n",
    "from reco_utils.recommender.surprise.surprise_utils import surprise_trainset_to_df\n",
    "from reco_utils.recommender.fastai.fastai_utils import hide_fastai_progress_bar, cartesian_product, score\n",
    "from reco_utils.evaluation.spark_evaluation import SparkRatingEvaluation, SparkRankingEvaluation\n",
    "from reco_utils.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "from reco_utils.evaluation.python_evaluation import rmse, mae, rsquared, exp_var\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"PySpark version: {}\".format(pyspark.__version__))\n",
    "print(\"Surprise version: {}\".format(surprise.__version__))\n",
    "print(\"PyTorch version: {}\".format(torch.__version__))\n",
    "print(\"Fast AI version: {}\".format(fastai.__version__))\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))\n",
    "print(\"CUDA version: {}\".format(get_cuda_version()))\n",
    "print(\"CuDNN version: {}\".format(get_cudnn_version()))\n",
    "n_cores = get_number_processors()\n",
    "print(\"Number of cores: {}\".format(n_cores))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYSPARK_PYTHON=/home/miguel/anaconda/envs/reco_full/bin/python\n",
      "env: PYSPARK_DRIVER_PYTHON=/home/miguel/anaconda/envs/reco_full/bin/python\n"
     ]
    }
   ],
   "source": [
    "%env PYSPARK_PYTHON=/home/miguel/anaconda/envs/reco_full/bin/python\n",
    "%env PYSPARK_DRIVER_PYTHON=/home/miguel/anaconda/envs/reco_full/bin/python\n",
    "\n",
    "#%env PYSPARK_PYTHON=/anaconda/envs/reco_full/bin/python\n",
    "#%env PYSPARK_DRIVER_PYTHON=/anaconda/envs/reco_full/bin/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Model parameters\n",
    "EPOCHS_CPU = 30\n",
    "EPOCHS_PYSPARK = 1#15\n",
    "EPOCHS_GPU = 1#5\n",
    "USER_COL = \"UserId\"\n",
    "ITEM_COL = \"MovieId\"\n",
    "RATING_COL = \"Rating\"\n",
    "TIMESTAMP_COL = \"Timestamp\"\n",
    "PREDICTION_COL = \"prediction\"\n",
    "SEED = 77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide fastai progress bar\n",
    "hide_fastai_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds to make sure out runs are reproducible\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "environments = {\n",
    "    \"als\": \"pyspark\",\n",
    "    \"sar_single_node\": \"python_cpu\",\n",
    "    \"svd\": \"python_cpu\",\n",
    "    \"fastai\": \"python_gpu\",\n",
    "    \"ncf\": \"python_gpu\",\n",
    "    \"rbm\": \"python_gpu\"\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    \"als\": [\"rating\", \"ranking\"],\n",
    "    \"sar_single_node\": [\"ranking\"],\n",
    "    \"svd\": [\"rating\", \"ranking\"],\n",
    "    \"fastai\": [\"rating\", \"ranking\"],\n",
    "    \"ncf\": [\"ranking\"],\n",
    "    \"rbm\": [\"ranking\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_params = {\n",
    "    \"rank\": 10,\n",
    "    \"maxIter\": EPOCHS_PYSPARK,\n",
    "    \"implicitPrefs\": False,\n",
    "    \"alpha\": 0.1,\n",
    "    \"regParam\": 0.05,\n",
    "    \"coldStartStrategy\": \"drop\",\n",
    "    \"nonnegative\": False,\n",
    "    \"userCol\": USER_COL,\n",
    "    \"itemCol\": ITEM_COL,\n",
    "    \"ratingCol\": RATING_COL,\n",
    "}\n",
    "\n",
    "sar_single_node_params = {\n",
    "    \"remove_seen\": True,\n",
    "    \"similarity_type\": \"jaccard\",\n",
    "    \"time_decay_coefficient\": 30,\n",
    "    \"time_now\": None,\n",
    "    \"timedecay_formula\": True,\n",
    "    \"col_user\": USER_COL,\n",
    "    \"col_item\": ITEM_COL,\n",
    "    \"col_rating\": RATING_COL,\n",
    "    \"col_timestamp\": TIMESTAMP_COL,\n",
    "}\n",
    "\n",
    "svd_params = {\n",
    "    \"n_factors\": 200,\n",
    "    \"n_epochs\": EPOCHS_CPU,\n",
    "    \"lr_all\": 0.005,\n",
    "    \"reg_all\": 0.02,\n",
    "    \"random_state\": SEED,\n",
    "    \"verbose\": False\n",
    "}\n",
    "\n",
    "fastai_params = {\n",
    "    \"n_factors\": 40, \n",
    "    \"y_range\": [0,5.5], \n",
    "    \"wd\": 1e-1,\n",
    "    \"max_lr\": 5e-3,\n",
    "    \"epochs\": EPOCHS_GPU\n",
    "}\n",
    "\n",
    "ncf_params = {\n",
    "    \"model_type\": \"NeuMF\",\n",
    "    \"n_factors\": 4,\n",
    "    \"layer_sizes\": [16,8,4],\n",
    "    \"n_epochs\": EPOCHS_GPU,\n",
    "    \"batch_size\": 1024,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"verbose\": 10\n",
    "}\n",
    "\n",
    "rbm_params = {\n",
    "    \"hidden_units\": 600, \n",
    "    \"training_epoch\": EPOCHS_GPU,\n",
    "    \"minibatch_size\": 60, \n",
    "    \"keep_prob\": 0.9,\n",
    "    \"with_metrics\": False\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"als\": als_params,\n",
    "    \"sar_single_node\": sar_single_node_params,\n",
    "    \"svd\": svd_params,\n",
    "    \"fastai\": fastai_params,\n",
    "    \"ncf\": ncf_params,\n",
    "    \"rbm\": rbm_params\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_als(train):\n",
    "    schema = StructType(\n",
    "    (\n",
    "        StructField(USER_COL, IntegerType()),\n",
    "        StructField(ITEM_COL, IntegerType()),\n",
    "        StructField(RATING_COL, FloatType()),\n",
    "        StructField(TIMESTAMP_COL, LongType()),\n",
    "    )\n",
    "    )\n",
    "    spark = start_or_get_spark()\n",
    "    return spark.createDataFrame(train, schema)\n",
    "\n",
    "def prepare_training_svd(train):\n",
    "    reader = surprise.Reader('ml-100k', rating_scale=(1, 5))\n",
    "    return surprise.Dataset.load_from_df(train.drop(TIMESTAMP_COL, axis=1), reader=reader).build_full_trainset()\n",
    "\n",
    "def prepare_training_fastai(train):\n",
    "    data = train.copy()\n",
    "    data[USER_COL] = data[USER_COL].astype('str')\n",
    "    data[ITEM_COL] = data[ITEM_COL].astype('str')\n",
    "    data = CollabDataBunch.from_df(data, user_name=USER_COL, item_name=ITEM_COL, rating_name=RATING_COL)\n",
    "    return data\n",
    "\n",
    "def prepare_training_ncf(train):\n",
    "    data = NCFDataset(train=train, \n",
    "                      col_user=USER_COL,\n",
    "                      col_item=ITEM_COL,\n",
    "                      col_rating=RATING_COL,\n",
    "                      col_timestamp=TIMESTAMP_COL,\n",
    "                      seed=SEED)\n",
    "    return data\n",
    "\n",
    "def prepare_training_rbm(train):\n",
    "    header = {\n",
    "        \"col_user\": USER_COL,\n",
    "        \"col_item\": ITEM_COL,\n",
    "        \"col_rating\": RATING_COL,\n",
    "    }\n",
    "    train_copy = train.copy()\n",
    "    train_copy.loc[:, RATING_COL] = train_copy[RATING_COL].astype(np.int32)\n",
    "    aff_train = AffinityMatrix(train_copy, **header)\n",
    "    return aff_train \n",
    "\n",
    "prepare_training_data = {\n",
    "    \"als\": prepare_training_als,\n",
    "    \"svd\": prepare_training_svd,\n",
    "    \"fastai\": prepare_training_fastai,\n",
    "    \"ncf\": prepare_training_ncf,\n",
    "    \"rbm\": prepare_training_rbm\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_rating_als(test):\n",
    "    schema = StructType(\n",
    "    (\n",
    "        StructField(USER_COL, IntegerType()),\n",
    "        StructField(ITEM_COL, IntegerType()),\n",
    "        StructField(RATING_COL, FloatType()),\n",
    "        StructField(TIMESTAMP_COL, LongType()),\n",
    "    )\n",
    "    )\n",
    "    spark = start_or_get_spark()\n",
    "    return spark.createDataFrame(test, schema)\n",
    "\n",
    "def prepare_rating_rbm(test):\n",
    "    header = {\n",
    "        \"col_user\": USER_COL,\n",
    "        \"col_item\": ITEM_COL,\n",
    "        \"col_rating\": RATING_COL,\n",
    "    }\n",
    "    test_copy = test.copy()\n",
    "    test_copy.loc[:, RATING_COL] = test_copy[RATING_COL].astype(np.int32)\n",
    "    aff_test = AffinityMatrix(test_copy, **header)\n",
    "    return  aff_test\n",
    "\n",
    "\n",
    "prepare_rating_data = {\n",
    "    \"als\": prepare_rating_als,\n",
    "    \"rbm\": prepare_rating_rbm,\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "prepare_ranking_data = {\n",
    "    \"als\": lambda train, test: prepare_test_als(df_train, df_test),\n",
    "    \"svd\": lambda train, test: prepare_test_svd(df_train, df_test),\n",
    "    \"fastai\": lambda train, test: prepare_test_fastai(df_train, df_test),\n",
    "    \"ncf\": lambda train, test: prepare_test_ncf(df_train, df_test),\n",
    "    \"rbm\": lambda train, test: prepare_test_rbm(df_train, df_test)\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_als(params, data):\n",
    "    symbol = ALS(**params)\n",
    "    with Timer() as t:\n",
    "        model = symbol.fit(data)\n",
    "    return model, t\n",
    "\n",
    "def train_svd(params, data):\n",
    "    model = surprise.SVD(**params)\n",
    "    with Timer() as t:\n",
    "        model.fit(data)\n",
    "    return model, t\n",
    "\n",
    "def train_fastai(params, data):\n",
    "    model = collab_learner(data, \n",
    "                           n_factors=params[\"n_factors\"],\n",
    "                           y_range=params[\"y_range\"],\n",
    "                           wd=params[\"wd\"]\n",
    "                          )\n",
    "    with Timer() as t:\n",
    "        model.fit_one_cycle(cyc_len=params[\"epochs\"], max_lr=params[\"max_lr\"])\n",
    "    return model, t\n",
    "\n",
    "def train_sar_single_node(params, data):\n",
    "    model = SARSingleNode(**params)\n",
    "    model.set_index(data)    \n",
    "    with Timer() as t:\n",
    "        model.fit(data)\n",
    "    return model, t\n",
    "    \n",
    "def train_ncf(params, data):\n",
    "    model = NCF(n_users=data.n_users, n_items=data.n_items, **params)\n",
    "    with Timer() as t:\n",
    "        model.fit(data)\n",
    "    return model, t\n",
    "    \n",
    "def train_rbm(params, data):\n",
    "    model = RBM(**params)\n",
    "    train = data.gen_affinity_matrix()\n",
    "    with Timer() as t:\n",
    "        model.fit(train, None)\n",
    "    return model, t\n",
    "    \n",
    "trainer = {\n",
    "    \"als\": lambda params, data: train_als(params, data),\n",
    "    \"svd\": lambda params, data: train_svd(params, data),\n",
    "    \"sar_single_node\": lambda params, data: train_sar_single_node(params, data), \n",
    "    \"fastai\": lambda params, data: train_fastai(params, data),\n",
    "    \"ncf\": lambda params, data: train_ncf(params, data),\n",
    "    \"rbm\": lambda params, data: train_rbm(params, data) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_als(model, test):\n",
    "    with Timer() as t:\n",
    "        preds = model.transform(test)\n",
    "    return preds, t\n",
    "\n",
    "\n",
    "def predict_svd(model, test):\n",
    "    with Timer() as t:\n",
    "        preds = [model.predict(row[USER_COL], row[ITEM_COL], row[RATING_COL])\n",
    "                       for (_, row) in test.iterrows()]\n",
    "        preds = pd.DataFrame(preds)\n",
    "        preds = preds.rename(index=str, columns={'uid': USER_COL, \n",
    "                                                 'iid': ITEM_COL,\n",
    "                                                 'est': PREDICTION_COL})\n",
    "        preds = preds.drop(['details', 'r_ui'], axis='columns')\n",
    "    return preds, t\n",
    "\n",
    "    \n",
    "def predict_fastai(model, test):\n",
    "    with Timer() as t:\n",
    "        preds = score(model, \n",
    "                      test_df=test, \n",
    "                      user_col=USER_COL, \n",
    "                      item_col=ITEM_COL, \n",
    "                      prediction_col=PREDICTION_COL)\n",
    "    return preds, t\n",
    "\n",
    "\n",
    "rating_predictor = {\n",
    "    \"als\": lambda model, test: predict_als(model, test),\n",
    "    \"svd\": lambda model, test: predict_svd(model, test),\n",
    "    \"fastai\": lambda model, test: predict_fastai(model, test),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_k_als(model, test, train):\n",
    "    with Timer() as t:\n",
    "        # Get the cross join of all user-item pairs and score them.\n",
    "        users = train.select(USER_COL).distinct()\n",
    "        items = train.select(ITEM_COL).distinct()\n",
    "        user_item = users.crossJoin(items)\n",
    "        dfs_pred = model.transform(user_item)\n",
    "\n",
    "        # Remove seen items.\n",
    "        dfs_pred_exclude_train = dfs_pred.alias(\"pred\").join(\n",
    "            train.alias(\"train\"),\n",
    "            (dfs_pred[USER_COL] == train[USER_COL]) & (dfs_pred[ITEM_COL] == train[ITEM_COL]),\n",
    "            how='outer'\n",
    "        )\n",
    "        top_k_scores = dfs_pred_exclude_train.filter(dfs_pred_exclude_train[\"train.\" + RATING_COL].isNull()) \\\n",
    "            .select('pred.' + USER_COL, 'pred.' + ITEM_COL, 'pred.' + PREDICTION_COL)\n",
    "\n",
    "        # In Spark, transformations are lazy evaluation\n",
    "        # Use an action to force execute and measure the test time \n",
    "        #top_k_scores.cache().count()\n",
    "    return top_k_scores, t\n",
    "    \n",
    "\n",
    "def recommend_k_sar_single_node(model, test, train):\n",
    "    with Timer() as t:\n",
    "        top_k_scores = model.recommend_k_items(test)\n",
    "    return top_k_scores, t\n",
    "\n",
    "\n",
    "def recommend_k_svd(model, test, train):\n",
    "    with Timer() as t:\n",
    "        preds_lst = []\n",
    "        for user in train[USER_COL].unique():\n",
    "            for item in train[ITEM_COL].unique():\n",
    "                preds_lst.append([user, item, model.predict(user, item).est])\n",
    "        top_k_scores = pd.DataFrame(data=preds_lst, columns=[USER_COL, ITEM_COL, PREDICTION_COL])\n",
    "        merged = pd.merge(train, top_k_scores, on=[USER_COL, ITEM_COL], how=\"outer\")\n",
    "        top_k_scores = merged[merged[RATING_COL].isnull()].drop(RATING_COL, axis=1)\n",
    "    return top_k_scores, t\n",
    "\n",
    "\n",
    "def recommend_k_fastai(model, test, train):\n",
    "    with Timer() as t: \n",
    "        total_users, total_items = model.data.classes.values()\n",
    "        total_items = np.array(total_items[1:])\n",
    "        total_users = np.array(total_users[1:])\n",
    "        test_users = test[USER_COL].unique()\n",
    "        test_users = np.intersect1d(test_users, total_users)\n",
    "        users_items = cartesian_product(test_users, total_items)\n",
    "        users_items = pd.DataFrame(users_items, columns=[USER_COL, ITEM_COL])\n",
    "        training_removed = pd.concat([users_items, train[[USER_COL, ITEM_COL]]]).drop_duplicates(keep=False)\n",
    "        top_k_scores = score(model, \n",
    "                             test_df=training_removed,\n",
    "                             user_col=USER_COL, \n",
    "                             item_col=ITEM_COL, \n",
    "                             prediction_col=PREDICTION_COL, \n",
    "                             top_k=TOP_K)\n",
    "    return top_k_scores, t\n",
    "\n",
    "\n",
    "def recommend_k_ncf(model, test, train):\n",
    "    with Timer() as t: \n",
    "        users, items, preds = [], [], []\n",
    "        item = list(train[ITEM_COL].unique())\n",
    "        for user in train[USER_COL].unique():\n",
    "            user = [user] * len(item) \n",
    "            users.extend(user)\n",
    "            items.extend(item)\n",
    "            preds.extend(list(model.predict(user, item, is_list=True)))\n",
    "        top_k_scores = pd.DataFrame(data={USER_COL: users, ITEM_COL:items, PREDICTION_COL:preds})\n",
    "        merged = pd.merge(train, top_k_scores, on=[USER_COL, ITEM_COL], how=\"outer\")\n",
    "        top_k_scores = merged[merged[RATING_COL].isnull()].drop(RATING_COL, axis=1)\n",
    "    return top_k_scores, t\n",
    "\n",
    "\n",
    "def recommend_k_rbm(model, test, train):\n",
    "    xtst = test.gen_affinity_matrix()\n",
    "    with Timer() as t:\n",
    "        top_k_scores, _ =  model.recommend_k_items(xtst)\n",
    "        top_k_scores = test.map_back_sparse(top_k_scores, kind=\"prediction\")\n",
    "    return top_k_scores, t\n",
    "\n",
    "\n",
    "ranking_predictor = {\n",
    "    \"als\": lambda model, test, train: recommend_k_als(model, test, train),\n",
    "    \"sar_single_node\": lambda model, test, train: recommend_k_sar_single_node(model, test, train),\n",
    "    \"svd\": lambda model, test, train: recommend_k_svd(model, test, train),\n",
    "    \"fastai\": lambda model, test, train: recommend_k_fastai(model, test, train),\n",
    "    \"ncf\": lambda model, test, train: recommend_k_ncf(model, test, train),\n",
    "    \"rbm\": lambda model, test, train: recommend_k_rbm(model, test, train),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_metrics_pyspark(test, predictions):\n",
    "    rating_eval = SparkRatingEvaluation(test, \n",
    "                                        predictions, \n",
    "                                        col_user=USER_COL, \n",
    "                                        col_item=ITEM_COL, \n",
    "                                        col_rating=RATING_COL, \n",
    "                                        col_prediction=PREDICTION_COL)\n",
    "    return {\n",
    "        \"RMSE\": rating_eval.rmse(),\n",
    "        \"MAE\": rating_eval.mae(),\n",
    "        \"R2\": rating_eval.exp_var(),\n",
    "        \"Explained Variance\": rating_eval.rsquared()\n",
    "    }\n",
    "    \n",
    "    \n",
    "def ranking_metrics_pyspark(test, predictions, k=10):\n",
    "    rank_eval = SparkRankingEvaluation(test, \n",
    "                                       predictions, \n",
    "                                       k=k, \n",
    "                                       col_user=USER_COL, \n",
    "                                       col_item=ITEM_COL, \n",
    "                                       col_rating=RATING_COL, \n",
    "                                       col_prediction=PREDICTION_COL, \n",
    "                                       relevancy_method=\"top_k\")\n",
    "    return {\n",
    "        \"MAP\": rank_eval.map_at_k(),\n",
    "        \"nDCG@k\": rank_eval.ndcg_at_k(),\n",
    "        \"Precision@k\": rank_eval.precision_at_k(),\n",
    "        \"Recall@k\": rank_eval.recall_at_k()\n",
    "    }\n",
    "    \n",
    "    \n",
    "def rating_metrics_python(test, predictions):\n",
    "    cols = {\n",
    "        \"col_user\": USER_COL, \n",
    "        \"col_item\": ITEM_COL, \n",
    "        \"col_rating\": RATING_COL, \n",
    "        \"col_prediction\": PREDICTION_COL\n",
    "    }\n",
    "    return {\n",
    "        \"RMSE\": rmse(test, predictions, **cols),\n",
    "        \"MAE\": mae(test, predictions, **cols),\n",
    "        \"R2\": rsquared(test, predictions, **cols),\n",
    "        \"Explained Variance\": exp_var(test, predictions, **cols)\n",
    "    }\n",
    "    \n",
    "    \n",
    "def ranking_metrics_python(test, predictions, k=10):\n",
    "    cols = {\n",
    "        \"col_user\": USER_COL, \n",
    "        \"col_item\": ITEM_COL, \n",
    "        \"col_rating\": RATING_COL, \n",
    "        \"col_prediction\": PREDICTION_COL\n",
    "    }\n",
    "    return {\n",
    "        \"MAP\": map_at_k(test, predictions, k=k, **cols),\n",
    "        \"nDCG@k\": ndcg_at_k(test, predictions, k=k, **cols),\n",
    "        \"Precision@k\": precision_at_k(test, predictions, k=k, **cols),\n",
    "        \"Recall@k\": recall_at_k(test, predictions, k=k, **cols)\n",
    "    }\n",
    "    \n",
    "    \n",
    "rating_evaluator = {\n",
    "    \"als\": lambda test, predictions: rating_metrics_pyspark(test, predictions),\n",
    "    \"svd\": lambda test, predictions: rating_metrics_python(test, predictions),\n",
    "    \"fastai\": lambda test, predictions: rating_metrics_python(test, predictions)\n",
    "}\n",
    "    \n",
    "    \n",
    "ranking_evaluator = {\n",
    "    \"als\": lambda test, predictions, k: ranking_metrics_pyspark(test, predictions, k),\n",
    "    \"sar_single_node\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "    \"svd\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "    \"fastai\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "    \"ncf\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "    \"rbm\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sizes = [\"100k\"]#, \"1m\"] # Movielens data size: 100k, 1m, 10m, or 20m\n",
    "#algorithms = [\"als\", \"svd\", \"sar_single_node\", \"fastai\", \"ncf\", \"rbm\"]\n",
    "algorithms = [\"rbm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# For each data size and each algorithm, a recommender is evaluated. \n",
    "df_results = pd.DataFrame()\n",
    "\n",
    "for data_size in data_sizes:\n",
    "    # Load the dataset\n",
    "    df = movielens.load_pandas_df(\n",
    "        size=data_size,\n",
    "        header=[USER_COL, ITEM_COL, RATING_COL, TIMESTAMP_COL]\n",
    "    )\n",
    "    print(\"Size of Movielens {}: {}\".format(data_size, df.shape))\n",
    "    \n",
    "    # Split the dataset\n",
    "    df_train, df_test = python_chrono_split(df, \n",
    "                                  ratio=0.75, \n",
    "                                  min_rating=1, \n",
    "                                  filter_by=\"user\", \n",
    "                                  col_user=USER_COL, \n",
    "                                  col_item=ITEM_COL, \n",
    "                                  col_timestamp=TIMESTAMP_COL)\n",
    "    print(\"Train set size: {}\".format(df_train.shape))\n",
    "    print(\"Test set size: {}\".format(df_test.shape))\n",
    "   \n",
    "    # Loop through the algos\n",
    "    for algo in algorithms:\n",
    "        print(\"\\nComputing {} algorithm on Movielens {}\".format(algo, data_size))\n",
    "          \n",
    "        # Data prep for training set\n",
    "        train = prepare_training_data.get(algo, lambda x:x)(df_train)\n",
    "        \n",
    "        # Get model parameters\n",
    "        model_params = params[algo]\n",
    "          \n",
    "        # Train the model\n",
    "        model, time_train = trainer[algo](model_params, train)\n",
    "        print(\"Training time: {}\".format(time_train))\n",
    "                \n",
    "        # Predict and evaluate\n",
    "        print(\"\\nEvaluating with {}\".format(algo))\n",
    "        test = prepare_rating_data.get(algo, lambda x:x)(df_test)\n",
    "        if \"rating\" in metrics[algo]:   \n",
    "            # Predict for rating\n",
    "            preds, time_rating = rating_predictor[algo](model, test)\n",
    "            print(\"Rating prediction time: {}\".format(time_rating))\n",
    "                        \n",
    "            # Evaluate for rating\n",
    "            ratings = rating_evaluator[algo](test, preds)\n",
    "            print(\"Rating metrics: \\n{}\".format(json.dumps(ratings, indent=4, sort_keys=True)))\n",
    "        \n",
    "        if \"ranking\" in metrics[algo]:\n",
    "            # Predict for ranking\n",
    "            top_k_scores, time_ranking = ranking_predictor[algo](model, test, df_train)\n",
    "            print(\"Ranking prediction time: {}\".format(time_ranking))\n",
    "            \n",
    "            # Evaluate for rating\n",
    "            rankings = ranking_evaluator[algo](test, top_k_scores, TOP_K)\n",
    "            print(\"Ranking metrics: \\n{}\".format(json.dumps(rankings, indent=4, sort_keys=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Movielens 100k: (100000, 4)\n",
      "Train set size: (74992, 4)\n",
      "Test set size: (25008, 4)\n"
     ]
    }
   ],
   "source": [
    "for data_size in data_sizes:\n",
    "    # Load the dataset\n",
    "    df = movielens.load_pandas_df(\n",
    "        size=data_size,\n",
    "        header=[USER_COL, ITEM_COL, RATING_COL, TIMESTAMP_COL]\n",
    "    )\n",
    "    print(\"Size of Movielens {}: {}\".format(data_size, df.shape))\n",
    "    \n",
    "    # Split the dataset\n",
    "    df_train, df_test = python_chrono_split(df, \n",
    "                                  ratio=0.75, \n",
    "                                  min_rating=1, \n",
    "                                  filter_by=\"user\", \n",
    "                                  col_user=USER_COL, \n",
    "                                  col_item=ITEM_COL, \n",
    "                                  col_timestamp=TIMESTAMP_COL)\n",
    "    print(\"Train set size: {}\".format(df_train.shape))\n",
    "    print(\"Test set size: {}\".format(df_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing rbm algorithm on Movielens 100k\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(60, 1681), b.shape=(1681, 600), m=60, n=600, k=1681\n\t [[node losses/MatMul_1 (defined at ../../reco_utils/recommender/rbm/rbm.py:249)  = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](IteratorGetNext/_5, Network_parameters/weight/read)]]\n\nCaused by op 'losses/MatMul_1', defined at:\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n    yield self.process_one()\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n    self.run()\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-69fa9cb140f9>\", line 26, in <module>\n    model.fit(train.gen_affinity_matrix())\n  File \"../../reco_utils/recommender/rbm/rbm.py\", line 769, in fit\n    self.generate_graph()\n  File \"../../reco_utils/recommender/rbm/rbm.py\", line 675, in generate_graph\n    obj = self.losses(self.v)  # objective function\n  File \"../../reco_utils/recommender/rbm/rbm.py\", line 453, in losses\n    obj = self.free_energy(vv) - self.free_energy(self.v_k)\n  File \"../../reco_utils/recommender/rbm/rbm.py\", line 249, in free_energy\n    phi_x = tf.matmul(x, self.w) + self.bh\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 2057, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4560, in mat_mul\n    name=name)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(60, 1681), b.shape=(1681, 600), m=60, n=600, k=1681\n\t [[node losses/MatMul_1 (defined at ../../reco_utils/recommender/rbm/rbm.py:249)  = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](IteratorGetNext/_5, Network_parameters/weight/read)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/envs/reco_full/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/reco_full/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/reco_full/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(60, 1681), b.shape=(1681, 600), m=60, n=600, k=1681\n\t [[{{node losses/MatMul_1}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](IteratorGetNext/_5, Network_parameters/weight/read)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-69fa9cb140f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRBM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_affinity_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;31m#model, time_train = trainer[algo](model_params, train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training time: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/Recommenders/reco_utils/recommender/rbm/rbm.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, xtr, xtst)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgibbs_protocol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Gibbs sampling update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m             \u001b[0mepoch_tr_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_minibatches\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# model train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_metrics\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/Recommenders/reco_utils/recommender/rbm/rbm.py\u001b[0m in \u001b[0;36mbatch_training\u001b[0;34m(self, num_minibatches)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_minibatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# minibatch loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mepoch_tr_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/reco_full/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/reco_full/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/reco_full/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/reco_full/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(60, 1681), b.shape=(1681, 600), m=60, n=600, k=1681\n\t [[node losses/MatMul_1 (defined at ../../reco_utils/recommender/rbm/rbm.py:249)  = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](IteratorGetNext/_5, Network_parameters/weight/read)]]\n\nCaused by op 'losses/MatMul_1', defined at:\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n    yield self.process_one()\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n    self.run()\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-69fa9cb140f9>\", line 26, in <module>\n    model.fit(train.gen_affinity_matrix())\n  File \"../../reco_utils/recommender/rbm/rbm.py\", line 769, in fit\n    self.generate_graph()\n  File \"../../reco_utils/recommender/rbm/rbm.py\", line 675, in generate_graph\n    obj = self.losses(self.v)  # objective function\n  File \"../../reco_utils/recommender/rbm/rbm.py\", line 453, in losses\n    obj = self.free_energy(vv) - self.free_energy(self.v_k)\n  File \"../../reco_utils/recommender/rbm/rbm.py\", line 249, in free_energy\n    phi_x = tf.matmul(x, self.w) + self.bh\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 2057, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4560, in mat_mul\n    name=name)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/miguel/anaconda/envs/reco_full/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(60, 1681), b.shape=(1681, 600), m=60, n=600, k=1681\n\t [[node losses/MatMul_1 (defined at ../../reco_utils/recommender/rbm/rbm.py:249)  = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](IteratorGetNext/_5, Network_parameters/weight/read)]]\n"
     ]
    }
   ],
   "source": [
    "    # Loop through the algos\n",
    "    for algo in algorithms:\n",
    "        print(\"\\nComputing {} algorithm on Movielens {}\".format(algo, data_size))\n",
    "          \n",
    "        # Get data\n",
    "        #train = prepare_training_data.get(algo, lambda x:x)(df_train)\n",
    "        header = {\n",
    "        \"col_user\": USER_COL,\n",
    "        \"col_item\": ITEM_COL,\n",
    "        \"col_rating\": RATING_COL,\n",
    "        }\n",
    "        train_copy = pd.concat([df_train, df_test])\n",
    "        train_copy.loc[:, RATING_COL] = train_copy[RATING_COL].astype(np.int32)\n",
    "        aff_train = AffinityMatrix(train_copy, **header)\n",
    "        aff_train._gen_index()\n",
    "        \n",
    "        # Get model parameters\n",
    "        model_params = params[algo]\n",
    "          \n",
    "        # Train the model\n",
    "        df_train_int = df_train.copy()\n",
    "        df_train_int.loc[:, RATING_COL] = df_train_int[RATING_COL].astype(np.int32)\n",
    "        train = AffinityMatrix(df_train_int, map_users=aff_train.map_users, map_items=aff_train.map_items, **header)\n",
    "        \n",
    "        model = RBM(**model_params)\n",
    "        model.fit(train.gen_affinity_matrix())\n",
    "        #model, time_train = trainer[algo](model_params, train)\n",
    "        print(\"Training time: {}\".format(time_train))\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_int = df_test.copy()\n",
    "df_test_int.loc[:, RATING_COL] = df_test_int[RATING_COL].astype(np.int32)\n",
    "test = AffinityMatrix(df_test_int, map_users=aff_train.map_users, map_items=aff_train.map_items, **header)\n",
    "top_k_scores, _ =  model.recommend_k_items(test.gen_affinity_matrix())\n",
    "top_k_scores = test.map_back_sparse(top_k_scores, kind=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        train._gen_index()\n",
    "        print(train.df_.head())\n",
    "        print(train.Nusers)#943\n",
    "        print(train.Nitems)#1598\n",
    "        ratings = train.df_[train.col_rating]  # ratings\n",
    "        itm_id = train.df_[\"hashedItems\"]  # itm_id serving as columns\n",
    "        usr_id = train.df_[\"hashedUsers\"]  # usr_id serving as rows\n",
    "        print(len(ratings)) #74992\n",
    "        print(len(itm_id)) #74992\n",
    "        print(len(usr_id)) #74992\n",
    "        print(list(ratings[:5]))\n",
    "        print(list(itm_id[:5]))\n",
    "        print(list(usr_id[:5]))\n",
    "        print(itm_id.max()) #1680\n",
    "        print(usr_id.max()) #942"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "AM = coo_matrix(\n",
    "            #(ratings, (usr_id, itm_id)), shape=(train.Nusers, train.Nitems)\n",
    "            (ratings, (usr_id, itm_id)), shape=(usr_id.max()+1, itm_id.max()+1)\n",
    "\n",
    "        ).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        if \"ranking\" in metrics[algo]:\n",
    "            # Predict for ranking\n",
    "            top_k_scores, time_ranking = ranking_predictor[algo](model, test, df_train)\n",
    "            print(\"Ranking prediction time: {}\".format(time_ranking))\n",
    "            \n",
    "            # Evaluate for rating\n",
    "            rankings = ranking_evaluator[algo](test, top_k_scores, TOP_K)\n",
    "            print(\"Ranking metrics: \\n{}\".format(json.dumps(rankings, indent=4, sort_keys=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Run notebooks to generate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For each data size and each algorithm, a recommender is evaluated. \n",
    "df_results = pd.DataFrame()\n",
    "\n",
    "for data_size in data_sizes:\n",
    "    for algorithm in algorithms:\n",
    "        print(algorithm, data_size)\n",
    "        # Execute the notebook\n",
    "        pm.execute_notebook(\n",
    "            notebooks[algorithm],\n",
    "            output_path,\n",
    "            parameters = dict(TOP_K=k, MOVIELENS_DATA_SIZE=data_size)\n",
    "        )\n",
    "        \n",
    "        # Read records from the notebook.\n",
    "        nb = pm.read_notebook(output_path)\n",
    "        \n",
    "        # Arrange results and save them into dataframe.\n",
    "        df_eval = nb.dataframe.transpose()\n",
    "        df_eval = df_eval.rename(columns=df_eval.iloc[0]).drop(['name', 'type', 'filename'])\n",
    "        df_eval.columns = [x.lower() for x in list(df_eval.columns)]\n",
    "        \n",
    "        if algorithm in [\"als\", \"svd\", \"fast\"]:\n",
    "            df_result = pd.DataFrame(\n",
    "                {\n",
    "                    \"Data\": data_size,\n",
    "                    \"Algo\": algorithm,\n",
    "                    \"K\": k,\n",
    "                    \"MAP\": df_eval['map'].item(),\n",
    "                    \"nDCG@k\": df_eval['ndcg'].item(),\n",
    "                    \"Precision@k\": df_eval['precision'].item(),\n",
    "                    \"Recall@k\": df_eval['recall'].item(),\n",
    "                    \"RMSE\": df_eval['rmse'].item(),\n",
    "                    \"MAE\": df_eval['mae'].item(),\n",
    "                    \"R2\": df_eval['rsquared'].item(),\n",
    "                    \"Explained Variance\": df_eval['exp_var'].item(),\n",
    "                    \"Train time\": df_eval['train_time'].item(),\n",
    "                    \"Test time\": df_eval['test_time'].item()\n",
    "                }, \n",
    "                index=[0]\n",
    "            )\n",
    "        # NOTE SAR algorithm does not predict rating scores so the rating metrics do not apply. \n",
    "        # Therefore, for SAR, the rating metrics are assigned with NAN.\n",
    "        elif algorithm in [\"sar\"]:\n",
    "            df_result = pd.DataFrame(\n",
    "                {\n",
    "                    \"Data\": data_size,\n",
    "                    \"Algo\": algorithm,\n",
    "                    \"K\": k,\n",
    "                    \"MAP\": df_eval['map'].item(),\n",
    "                    \"nDCG@k\": df_eval['ndcg'].item(),\n",
    "                    \"Precision@k\": df_eval['precision'].item(),\n",
    "                    \"Recall@k\": df_eval['recall'].item(),\n",
    "                    \"RMSE\": np.nan,\n",
    "                    \"MAE\": np.nan,\n",
    "                    \"R2\": np.nan,\n",
    "                    \"Explained Variance\": np.nan,\n",
    "                    \"Train time\": df_eval['train_time'].item(),\n",
    "                    \"Test time\": df_eval['test_time'].item()\n",
    "                }, \n",
    "                index=[0]\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"{} is not a recognized algorithm\".format(algorithm))\n",
    "        df_results = df_results.append(df_result, ignore_index=True)\n",
    "        \n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (reco_full)",
   "language": "python",
   "name": "reco_full"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
